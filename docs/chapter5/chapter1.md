# LoRA(五)QLoRA的优中之优

##### 作者：小韩 前快手高级工程师，前58高级工程师，现Datawhale社区成员
##### 原创不易，转载请保留署名


# 模型的权重
在我们进行的ChatML的大模型中，究竟是什么权重，这个其实很容易理解，在我们之前讲解的浮点数中，我们已经明白浮点数的原理是什么，那么在大模型当中，权重是如何存储的，这里我来讲解一下，权重的本质也是二进制，只不过是一种浮点数的形式来表示，如果严谨一点来表示的话，就是“矩阵+浮点数”，这个就是权重。那么什么是权重的存储方式，就是我们常用的存储类型，比如8字节的浮点数，4字节的浮点数和半精度的浮点数等等方式


# 量化的分类
之前的文章中讲解了INT8的3个量化算法，AbsMax、ZeroPoint、Quantile，除了INT8量化之外还有其他常见的方式如下所示：
FP32 ，4字节
FP16/BF16 ，2个字节
4BIT，0.5字节
混合精度方式
其他量化等。
	
这里我们继续进行QLoRA的知识，我们知道QLoRA的优势就是能在单卡上训练70亿参数模型，显著降低显存需求同时保持较好性能，而QLoRA的核心技术栈就是：QLoRA = 4bit量化 + LoRA + 双重量化 + 分页器优化
4bit量化：节省内存，将于训练模型的权重量化为4位的精度
LoRA：通过低秩矩阵来进行参数高效微调
双重量化：对量化参数进行再次量化，进一步压缩存储，这里主要是对缩放因子处理，此参数用可以来控制LoRA权重
分页器优化：管理显存，通过分页优化器状态在训练过程中减少资源占用，从而防止内存溢出


# 4bit的作用
模型的权重我们既然知道是浮点数，那么只要是数字，不管是浮点数还是正常的数字，肯定都是有一个范围的，我们只需要过滤这个范围就可以知道范围中都有哪些内容。而4bit就是这样的量化方式，通过均匀分布量化，并且可以减少误差，从而进行微调。
那么有没有更好的方式，在Transformer架构中，有个更优的方式，那就是4bit的优化版，nf4
nf4如何运行，原理分为三步
1，分块量化：将权重矩阵分成小块，每块单独处理，每个单独块计算一个独立的缩放因子。
2，分位数映射：我们之前讲过分位数，根据第一步的分块，建立映射，这里的映射是NF4算法本身就有一套查找表，里面有16个值，这些值时正态分布的最优分位点。
3，动态反量化：在训练时，使用这个表来找到分布的点，然后通过映射找回权重，进行恢复，从而保证结果的准确性。
简而言之就是，权重分成64块，然后通过缩放因子，对每块进行nf4量化，然后存储在nf4的表中（0-15），当使用或推理的时候，通过nf4的表并且乘上缩放因子然后得到权重。



# 双重量化的作用
在对权重进行分块之后，每个单独的块会有一个独立的缩放因子，而这个缩放因子，在默认的情况下是4个字节的类型，那么在QLoRA当中，发现这个缩放因子还可以再进一步压缩，量化成INT8或者INT16的精度，一般都是用INT8，已足够应用大部分的模型。而通过这种量化，这样就会计算出一个超缩放因子和零点（Scale和zero-point）。在大模型中比如65B的参数模型，这种双重量化可以让整个BaseModel至少节约1GB以上的显存。
‌简而言之就是，将分块量化后的‌缩放因子‌（原占4字节）当作数据，再进行一次INT8量化，生成新的‌超缩放因子‌和‌零点‌。这样每块缩放因子存储开销从4字节压缩到占用更小的字节。




# 分页器优化的作用
在操作系统中，有进程的swap分页的概念，这里分页优化器的作用就是参考了操作系统中的分页swap，之所以分页优化器使用这种方式，可以让GPU显存和CPU内存（RAM）直接进行动态交互，从而提升大模型减少对显存的占用。当然，前面用进程的概念，这个只是为了方便理解，但是分页器优化与操作系统分页还是有区别的，‌具体不同是‌：操作系统分页用于进程内存管理，分页优化器针对优化器状态。
	
在训练模型的时候，我们通过Adam或者AdamW来进行，他们的本质是在训练参数的时候，存储两个FP32状态，动量(m状态)和方差(v状态)。
1，动量，记录历史梯度的指数加权平均值。
2，方差，记录历史梯度平方的指数加权平均值。
在在QLoRA的训练过程中，如果我们使用的是paged_adamw ，那么会智能地决定哪些内存页是当前计算所需的。
‌简而言之就是，QLoRA的分页器优化，就是让GPU只需要计算所必需的优化器状态。它有效地将LoRA训练中的主要进行了内存管理，从而实现了在单张低显存卡上训练大模型的壮举。




# 最后结语

大模型虽然在蓬勃发展，但是发展到某个阶段后，如果不掌握微调，很快我们就会被各种阉割的数据，失真的数据被淹没在“数字饲料”或者“信息饲料”当中，成为被驯化的一环，掌握微调在未来的某个节点将会是一项必备的技能。总而言之，经过前面文章对LoRA的了解，到现在对 QLoRA 的代码示例和量化的原理了解，我相信各位读者已经慢慢的在微调的道路上有了自己的见解，并且也越走越远，最后的结语，我要说的是，实践出真知，在训练的过程中，掌握原理是前提，敢于挑战困难是勇气，持续迭代才是通向高性能企业级 LLM 的最终路径。

