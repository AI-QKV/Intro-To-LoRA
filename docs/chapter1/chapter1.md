LoRA深入浅出\(一\) LoRA的原理

作者：殷韩（前快手高级工程师，前58高级工程师，现Datawhale社区成员）

![](https://github.com/AI-QKV/Intro-To-LoRA/blob/main/docs/chapter1/images/001.png)


LoRA的图片示例

#LoRA原理

在众多训练模型的方法中，高效微调参数是绕不过的话题。

那么高效微调参数，为什么有那么大的魔力，是因为，高效微调参数，它用轻量级的参数，实现了接近全量微调的性能效果，同时显著降低了计算成本、存储需求和训练时间‌。

而其中LoRA又在这方面又具有独特的优势

LoRA公式

$$W' = W + \frac{\alpha}{r} (AB)$$

说明：

'w 表示的是训练后的模型，也就是 new模型

w 是base Model，原始模型，基础模型，这个取决你基于什么模型来进行

r 是rank，论文建议是大于8，小于64，超过128 丧失高效性且可能过拟合

a 是，alpha表示缩放因子，用来控制LoRA的矩阵参数的权重，论文中的建议 alpha=2r或alpha=r

AB是LoRA中的矩阵，A\(input, r\), B\(r, output\)

以上内容就是LoRA的公式。

![](https://github.com/AI-QKV/Intro-To-LoRA/blob/main/docs/chapter1/images/002.png)

图片为LoRA代码示例


#LoRA及模型级别

那么究竟如何使用LoRA进行训练呢？在LoRA当中，其原理是对模型的target\_modules进行替换或者包装，它并不会直接修改比如q\_proj, v\_proj层的内容（如果不熟悉target\_modules，请先去学习Transformers）。

对于不同的模型，有不同的规则，比如我们按下面的参数量来进行

LLM大小为10B左右，rank的起始可以从4开始，也可以从8开始，这种是适用于大多数任务，尤其是在计算预算有限的情况下使用

LLM大小为32B左右，可以从16开始，论文中的建议是8起步，64以内是最佳的效果，所以对于32B模型来说，要达到性能和参数量之间良好的平衡，需要设置比8更高的rank，所以这里从16开始也是符合规范的

LLM大小为64B左右，可以从24开始，且32开始也可以接受，根据微调效果，来达到性能和参数量之间的良好平衡点。


#LoRA和数据集

数据集，对于不同的模型，需要的数据也不相同

如下参考

LLM大小为10B左右，3000条或者5000条高质量数据。

这种量级的数据，可以进行角色扮演/知识注入/简单分类。

LLM大小为32B左右，5000条或者1万条高质量数据，建议1万条。

可以进行复杂推理/多轮对话/专业QA。

LLM大小为64B左右，1万条或者2万条高质量数据，这种量级数据，可以进行企业级应用/跨领域决策。


#影响LoRA的因素

在微调过程中，除了rank还有哪些因素会影响

缩放因子\(a也称为alpha\) 它的作用控制参数权重。

如果这个值过小，会导致梯度失衡，破坏训练的稳定性，无法有效学习新任务特征。

如果这个值过大，压制原始模型的知识，出现影响baseModel原来的权重，造成预训练知识覆盖和新任务过拟合，降低泛化能力‌导致学的不够准确

LR学习率，优化步长。控制参数更新的快慢

学习率的本质是这样的，预测的结果和真实的结果之间的差异，如果预测值和真实值一致，那么这个学习率就不用调整。

如果预测值和真实值有所不同，才需要调整学习率，合适的值能帮助模型高效、稳定地找到最优解‌

优化器，优化算法。决定如何使用梯度更新参数。常见的有，SGD，AdamW，预热cosine等等，那么在LoRA中应该用那个，目前常用的是AdamW

LoRA参数比较少，AdamW能更高效地平衡新旧知识。


#BaseModel选择

这个BaseModel是基模型，我们要基于这个BaseModel来进行微调。

比如我们的业务是问答，我们就要选择一个问答的BaseModel来进行。如果我们的业务是图文生成那么我们就要选择一个图文生成的来进行。

根据不同的业务来选择这个BaseModel，当然如果实例可以的话，可以自研一个BaseModel，基于这个BaseModel来进行自己的业务。

市面上的BaseModel也有很多，比如Qwen系列，DeepSeek系列，以及Huggingface上一些被训练过的模型系统等等。


#LoRA训练模型的目的

我们对模型的训练最终目的大概可以分为3种类型。

1，行为对齐，让模型学会如何根据人类指令给出特定风格或风格的回答

2，知识注入，注入模型在预训练数据中没有学到的最新、私有或专业知识

3，模式学习，学习特点行业的专业术语、数据结构和业务逻辑


#LoRA训练的轮次

那么LoRA具体如何训练呢，以及如何设置轮次，首先我们要明白几个训练相关的参数

per\_device\_train\_batch\_size，作用是，单次前向传播的数据量，我们用32B模型示例，可以写8或者16

这个参数我用一个例子来表示，假设我有一个文本，里面有100个问答，这个per\_device\_train\_batch\_size‌设置为4，那么就是从这个文本中，取出4个来当作一个批次来处理。

gradient\_accumulation\_steps，作用是梯度累积步数，我们用32B模型示例，可以写 1或2

这个参数简单来说，梯度累积是一种‌时间换空间‌的策略。需要根据有效批次和单个批次数量来设置，如果这样讲太复杂的话，我用公式来表示，gradient\_accumulation\_steps = \(有效批次 / per\_device\_train\_batch\_size\)

比如有效批次是8，而per\_device\_train\_batch\_size单次前向传播是2，那么这个gradient\_accumulation\_steps就是4，那么设置成4就可以。

effective\_batch\_size，作用是有效的训练批量大小，这个值通常我们不需要设置，但是我们要明白这个参数的作用。

这个参数的公式是：effective\_batch\_size = per\_device\_train\_batch\_size × gradient\_accumulation\_steps × GPU数量

num\_train\_epochs，作用训练轮次，我们用32B模型示例，可以写 1到3。

简而言之就是，整个数据集被遍历的次数。


#最后结语

经过对 LoRA 核心公式、参数选择、数据规模及训练要素的深入剖析，我们已经构建了一套清晰且严谨的 LoRA 微调体系。然而，真正的模型优化，其复杂性远超理论。最后的结语，我要说的是，实践出真知，在训练的过程中，掌握原理是前提，敢于挑战困难是勇气，持续迭代才是通向高性能企业级 LLM 的最终路径。

